## Day 1 Study Notes: Object Detection Fundamentals

### Session 1: Introduction to Computer Vision
*   **What is Computer Vision (CV)?**
    *   A field of Artificial Intelligence (AI) that enables computers to "see" and interpret visual information from the world.
    *   It involves processing, analyzing, and understanding digital images and videos.
*   **Role of CV in AI:**
    *   Crucial for developing intelligent systems that can interact with the physical world.
    *   Applications include autonomous driving, facial recognition, medical imaging analysis, augmented reality, and robotics.

### Session 2: Image Formation & Pixel-Level Operations
*   **Image Formation Basics:**
    *   Images are represented as grids of pixels (picture elements).
    *   Each pixel holds intensity (grayscale) or color (RGB, etc.) information.
    *   Understanding how light interacts with objects and sensors to form an image is fundamental.
*   **Pixel-Level Operations:**
    *   Basic manipulations applied directly to individual pixel values or small neighborhoods of pixels.
    *   Examples include:
        *   Brightness/Contrast adjustment.
        *   Grayscale conversion.
        *   Simple image filtering (e.g., blurring, sharpening).
        *   Thresholding (converting to binary images).

### Session 3: Introduction to Object Detection
*   **What is Object Detection?**
    *   A computer vision task that involves identifying and localizing objects within an image or video.
    *   It typically outputs bounding boxes around detected objects and assigns a class label to each.
*   **Components of Object Detection:**
    *   **Classification:** Identifying *what* object is present (e.g., cat, dog, car).
    *   **Localization:** Identifying *where* the object is in the image (e.g., drawing a bounding box around it).
    *   **Feature Extraction:** Deriving meaningful information from raw pixel data to represent objects.
    *   **Prediction:** Using the extracted features to classify and localize objects.

### Session 4: Classification vs. Localization vs. Segmentation
*   **Classification vs. Localization:**
    *   **Classification:** Answers "What is in this image?" (e.g., "This image contains a cat"). Outputs a single class label for the entire image.
    *   **Localization:** Answers "Where is the object in this image?" (e.g., "There is a cat at these coordinates"). Outputs bounding box coordinates for a *single* object.
    *   **Object Detection:** Combines both, answering "What objects are where in this image?" (e.g., "A cat is here, a dog is there"). Outputs multiple bounding boxes and class labels for multiple objects.
*   **Object Detection vs. Segmentation:**
    *   **Object Detection:** Provides coarse localization with bounding boxes.
    *   **Semantic Segmentation:** Classifies every pixel in an image into a predefined class (e.g., all "car" pixels are red, all "road" pixels are blue). Does not distinguish between individual instances of the same class.
    *   **Instance Segmentation:** Identifies and delineates each individual object instance in an image at a pixel level (e.g., separates "car 1" from "car 2" and provides a pixel-level mask for each). More detailed than object detection.

### Session 5: Early Object Detection Methods & Evolution
*   **Early Object Detection Methods:**
    *   Pre-deep learning approaches often relied on handcrafted features and classical machine learning algorithms.
    *   Characterized by sequential processing steps: feature extraction, classification, and non-maximal suppression.
*   **Evolution of Object Detection:**
    *   Transitioned from traditional methods (like Haar Cascades, HOG+SVM) to deep learning-based methods (R-CNN family, YOLO, SSD, Transformers).
    *   Deep learning models automatically learn features directly from data, leading to significant performance improvements in accuracy and speed.